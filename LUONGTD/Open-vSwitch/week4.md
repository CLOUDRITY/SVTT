# The Design and Implementation of Open vSwitch
## [0. Introduction] (#intro)
## [1. Design Contraints](#constraint)
## [2. Design](#design)
---
## <a name="intro"></a> 0. Introduction
Sự gia tăng ảo hóa server đã mang đến một thay đổi cơ bản trong mạng trung tâm dữ liệu (datacenter networking). Một lớp truy cập mạng mới được tạo ra, trong đó, hầu hết các cổng mạng là ảo và do đó, hop switch đầu tiên cho workload thường được đặt nằm trong hypervisor. Trong thời kỳ đầu, những hypervisor "vSwitch" chủ yếu cung cấp những kết nối mạng cơ bản. Các hypervisor "vSwitch" mở rộng mạng L2 vật lý để chứa các máy ảo. Khi khối lượng workload ảo hóa tăng lên, cách tiếp cận này bộc lộ các giới hạn như: việc cấu hình lại và chuẩn bị một mạng vật lý cho workload mới sẽ làm chậm quá trình cung cấp (provisioning) của chúng; việc ghép nối (coupling) workload với các phân đoạn L2 vật lý cũng hạn chế tính di động và khả năng mở rộng của nền tảng mạng.

Những hạn chế trên dẫn đến sự xuất hiện của ảo hóa mạng. Trong môi trường mạng ảo hóa, các switch ảo là thành phần chính cung cấp dịch vụ mạng cho các VMs, để lại nhiệm vụ vận chuyển các gói IP tunneled giữa hypervisors cho các mạng trung tâm dữ liệu vật lý. Cách tiếp cận này cho phép các mạng ảo được tách rời khỏi các nền tảng mạng vật lý cơ bản, và bằng cách tận dụng tính linh hoạt của các bộ xử lý đa năng, các switch ảo có thể cung cấp cho các VM, cho những clients và quản trị viên các trừu tượng mạng logic, các dịch vụ, công cụ giống với một mạng vật lý chuyên dụng.

Việc ảo hóa mạng đòi hỏi phải có một switch ảo được kết nối dây - chức năng chuyển tiếp (forwarding functionality) phải được nối dây trên cơ sở cổng ảo để phù hợp với các trừu tượng mạng logic được cấu hình bởi các quản trị viên. Cách tiếp cận này khác biệt với các switch ảo đời đầu, khi mà một pipeline chuyển tiếp tĩnh (được hard coded) cũng đủ để cung cấp cho các máy ảo với kết nối L2 đến các mạng vật lý.

## <a name="constraint"></a> 1. Design constraints
**Resource sharing.** Các mục tiêu hiệu suất của các thiết bị mạng truyền thống ưu tiên thiết kế sử dụng tài nguyên phần cứng chuyên dụng để đạt được hiệu suất line rate trong điều kiện trường hợp xấu nhất. Với một switch ảo, bảo tồn tài nguyên là yếu tố quan trọng hơn. Việc switch có thể theo kịp với line rate xấu nhất hay không là thứ yếu để tối đa hóa tài nguyên có sẵn cho chức năng chính của hypervisor: chạy workload của người dùng. So với môi trường vật lý, mạng trong môi trường ảo hóa tối ưu hóa cho trường hợp phổ biến thay vì trường hợp xấu nhất. Không phải việc tối ưu trong tình huống xấu nhất là không quan trọng bởi vì chúng cũng xuất hiện trong thực tế. Quét cổng (port scan), kết nối peer-to-peer máy chủ và giám sát mạng đều tạo ra các mẫu lưu lượng truy cập bất thường nhưng phải được hỗ trợ một cách thích hợp. Nguyên tắc này dẫn tới việc sử dụng flow caching và các hình thức caching khác, mà trong các trường hợp phổ biến làm giảm hiệu suất của CPU và tăng tỷ lệ chuyển tiếp.

**Placement.** Việc đặt các switch ảo ở rìa mạng là một việc (source) vừa đơn giản vừa phức tạp. Có thể cho rằng, vị trí topological như một lá (leaf), cũng như việc gắn liền với hypervisor và máy ảo đã loại bỏ nhiều vấn đề về mạng. Tuy nhiên, vị trí phức tạp có chiều hướng gia tăng. Điều này khá phổ biến đối với một switch ảo duy nhất để có hàng nghìn switch ảo như các thiết bị chuyển mạch của nó trong một mạng lưới các tunneled IP point-to-point giữa các hypervisor. Các switch ảo nhận các bản cập nhật trạng thái chuyển tiếp khi các máy ảo khởi động, di chuyển và tắt và trong khi các switch ảo có các cổng mạng vật lý tương đối ít (theo chuẩn mạng), các thay đổi trong hypervisor từ xa có thể ảnh hưởng đến trạng thái cục bộ. Đặc biệt là trong việc triển khai lớn hơn hàng ngàn (hoặc nhiều hơn) của các hypervisor, trạng thái chuyển tiếp có thể liên tục. Ví dụ điển hình của một thiết kế ảnh hưởng bởi nguyên tắc này được thảo luận trong bài báo là thuật toán phân loại Open vSwitch, được thiết kế cho các bản cập nhật (có độ phức tạp) O(1).

**SDN, usecases, and ecosystem.** Open vSwitch có 3 yêu cầu đặc biệt khiến thiết kế của nó khác biệt so với các switch ảo khác:
Đầu tiên, Open vSwitch là một switch OpenFlow. Nó được cố tình không gắn với một ngăn xếp điều khiển mạng tích hợp theo chiều dọc, mục đích duy nhất, mà thay vào đó có thể lập trình lại thông qua Open-Flow. Điều này giải thích với một mô hình datapath tính năng của các switch ảo khác: tương tự như các ASIC chuyển tiếp, các đường ống xử lý gói tin của chúng được cố định. Chỉ có thể cấu hình các tính năng được sắp xếp trước. (Switch ảo Hyper-V có thể được mở rộng bằng cách thêm các mô-đun nhị phân, nhưng thông thường mỗi mô-đun chỉ thêm một tính năng một mục đích khác vào datapath.)

Sự linh hoạt của OpenFlow là điều cần thiết trong những ngày đầu của SDN nhưng với các trường hợp sử dụng nâng cao, như ảo hóa mạng, dẫn đến pipeline xử lý gói dài, và do đó tải phân loại cao hơn so với truyền thống trong các switch ảo. Để ngăn không cho Open vSwitch tiêu thụ nhiều tài nguyên hypervisor hơn so với các switch ảo cạnh tranh, nó buộc phải thực hiện lưu trữ bộ nhớ đệm.
Thứ ba, không giống như bất kỳ switch ảo (lớn) nào khác, OpenvSwitch là mã nguồn mở và đa nền tảng. Ngược lại với các switch ảo nguồn đóng mà tất cả hoạt động trong một môi trường duy nhất, môi trường Open vSwitch thường được chọn bởi người dùng chọn phân phối hệ điều hành và hypervisor. Điều này đã buộc thiết kế OpenvSwitch trở nên khá mô-đun và di động

## <a name="design"></a> 2. Design
### 2.0. Overview
Trong Open vSwitch, có hai thành phần chính chuyển tiếp gói tin trực tiếp. Thành phần đầu tiên là ```ovs-vswitchd```, một daemon không gian người dùng về cơ bản giống với một hệ điều hành và môi trường hoạt động khác. Thành phần chính khác, ```datapath kernel module``` thường được viết đặc biệt cho hệ điều hành máy chủ để thực hiện. 

![](images/2-OVS-Architecture/ovs_packet_flow.jpg)

Hình trên mô tả cách hai thành phần chính của OVS làm việc cùng nhau để chuyển tiếp các gói tin. Module datapath trong kernel nhận các gói tin đầu tiên, từ một NIC vật lý hoặc một NIC ảo của VM. Hoặc ovs-vswitchd đã hướng dẫn datapath cách xử lý các gói thuộc loại này, hoặc nó không có. Trong trường hợp trước đây, mô đun datapath chỉ đơn giản là làm theo các instruction, được gọi là các action, được đưa ra bởi ```ovs-vswitchd```, liệt kê các cổng hoặc đường dẫn vật lý để truyền gói tin. Các action cũng có thể chỉ định các sửa đổi gói, lấy mẫu gói hoặc hướng dẫn để thả gói. Trong trường hợp khác, nơi mà datapath không được cho biết phải làm gì với gói tin, nó đưa gói tin đến ```ovs-vswitchd```. Trong không gian người dùng, ```ovs-vswitchd``` xác định gói tin sẽ được xử lý như thế nào, sau đó nó chuyển gói dữ liệu trở lại datapath với xử lý mong muốn. Thông thường, ```ovs-vswitchd``` cũng thông báo cho các datapath cache lại các action, để xử lý các gói tương tự trong tương lai.

Trong Open vSwitch, flow caching đã phát triển rất nhiều theo thời gian; ban đầu datapath là một bộ nhớ cache microflow, về cơ bản là caching cho mỗi quyết định chuyển tiếp kết nối giao thông. Trong các phiên bản sau, datapath có hai lớp bộ nhớ đệm: một bộ nhớ đệm microflow cache và một lớp thứ cấp, được gọi là bộ đệm megaflow cache, lưu trữ các quyết định chuyển tiếp cho tập hợp lưu lượng vượt quá các kết nối riêng lẻ.

Open vSwitch thường được sử dụng như một SDN switch, và cách chính để kiểm soát chuyển tiếp là OpenFlow. Thông qua một giao thức nhị phân (binary) đơn giản, OpenFlow cho phép một bộ điều khiển thêm, loại bỏ, cập nhật, giám sát và thu thập số liệu thống kê trên các bảng lưu lượng (flow table) và luồng (flow) của chúng, cũng như chuyển các gói đã chọn tới bộ điều khiển và đưa các gói tin từ bộ điều khiển vào switch. Trong Open vSwitch, ```ovs-vswitchd``` nhận các bảng lưu lượng OpenFlow từ một bộ điều khiển SDN (SDN controller), khớp với bất kỳ gói nào nhận được từ mô đun datapath đối với các bảng OpenFlow này, tập hợp các hành động được áp dụng và cuối cùng lưu trữ kết quả trong kernel datapath. Điều này cho phép các mô-đun datapath vẫn không biết về các chi tiết của giao thức dây OpenFlow, tiếp tục đơn giản hóa nó. Từ góc độ của bộ điều khiển OpenFlow, việc caching và phân tách thành thành phần user và kernel là chi tiết triển khai vô hình: từ góc độ của bộ điều khiển, mỗi gói truy cập một loạt các bảng lưu lượng OpenFlow và switch sẽ tìm flow ưu tiên cao nhất thỏa mãn gói và thực thi các OpenFlow action của nó.

Mô hình lập trình luồng của Open vSwitch phần lớn xác định các trường hợp sử dụng nó có thể hỗ trợ. Open vSwitch có nhiều phần mở rộng cho OpenFlow chuẩn để chứa (accommodate) ảo hóa mạng. Ta sẽ thảo luận về các phần mở rộng này sau, nhưng trước đó, ta tập trung vào các khía cạnh quan trọng về hiệu suất của thiết kế này: phân loại gói (packet classification) và kernel-userspace interface.

### 2.1. Packet Classification
Phân loại gói tin (theo cách algorithmic) là tốn kém đối với các bộ vi xử lý mục đích chung. Phân loại gói trong ngữ cảnh của OpenFlow đặc biệt tốn kém vì tính tổng quát của dạng match, có thể kiểm tra bất kỳ kết hợp địa chỉ Ethernet, địa chỉ IPv4 và IPv6, cổng TCP và UDP và nhiều trường khác, bao gồm siêu dữ liệu gói (packet megadata) chẳng hạn như cổng switch nhập (ingress). OpenvSwitch sử dụng một bộ phân loại tìm kiếm không gian (```tuple space search``` classifier) cho tất cả các hoạt động phân loại gói tin của nó, cả kernel và userspace. Để hiểu cách hoạt động của tuple space search, giả sử rằng tất cả các flow trong flow table Open vSwitch khớp trên cùng các trường theo cùng một cách, ví dụ: tất cả các flow khớp với địa chỉ Ethernet nguồn và đích nhưng không có trường nào khác. Một tuple search classifier thực hiện một flow table như một bảng băm đơn. Nếu bộ điều khiển sau đó thêm các luồng mới với một hình thức match khác nhau, trình phân loại tạo ra một bảng băm thứ hai mà các băm trên các trường được match trong các luồng đó. (Tuple của bảng băm trong bộ phân loại tìm kiếm không gian tuple là đúng, tập hợp các trường tạo thành khóa của bảng băm, nhưng chúng ta thường tham khảo bảng băm như bộ tuple, như một cách viết tắt hữu ích.) Với hai bảng băm, một thao tác tìm kiếm phải nhìn vào cả hai bảng băm. Nếu không có kết quả phù hợp, flow table không chứa kết quả phù hợp; nếu có một match trong một bảng băm, flow đó là kết quả; nếu có một match trong cả hai, thì kết quả là flow có mức độ ưu tiên cao hơn. Khi trình điều khiển tiếp tục thêm nhiều flow hơn với các hình thức match mới, trình phân loại tương tự mở rộng để bao gồm một bảng băm cho mỗi đối sánh duy nhất và tìm kiếm của trình phân loại phải xem xét trong mọi bảng băm.

Tuple space search hoạt động tốt với các flow table mà ta thấy trong thực tế và nó có ba thuộc tính đặc sắc hơn so với các thuật toán phân loại cây quyết định. Đầu tiên, nó hỗ trợ cập nhật constant-time hiệu quả (một cập nhật dịch sang một hoạt động bảng băm). Điều này giúp tuple space search phù hợp để sử dụng với môi trường ảo hóa, nơi một bộ điều khiển tập trung (centralized controller) có thể thêm và loại bỏ các flow thường xuyên, đôi khi nhiều lần mỗi giây cho mỗi hypervisor, để đáp ứng với những thay đổi trong toàn bộ trung tâm dữ liệu. Thứ hai, tuple space search tổng quát hóa một số trường tùy ý của các trường tiêu đề (header) của gói tin mà không cần có bất kỳ thay đổi thuật toán nào. Cuối cùng, tuple space search sử dụng số flow trong bộ nhớ với độ phức tạp là tuyến tính.

Chi phí tương đối của phân loại gói tin được tăng thêm đáng kể bởi số lượng lớn các flow table mà các bộ điều khiển SDN phức tạp sử dụng. Ví dụ, flow table được cài đặt bởi bộ điều khiển ảo hóa mạng VMware sử dụng tối thiểu khoảng 15 lần tra cứu bảng cho mỗi gói trong đường dẫn (pipeline) xử lý gói của nó. Pipeline bị điều khiển (driven) bởi hai yếu tố: một là giảm các giai đoạn thông qua sản xuất chéo thường làm tăng đáng kể kích thước flow table và hai là các developer thường ưu tiên mô đun hóa thiết kế pipeline. Vì vậy, việc giảm số lượng các bảng tra cứu lưu lượng một gói tin yêu cầu thậm chí còn quan trọng hơn hiệu suất của một tra cứu phân loại.

### 2.2. OpenFlow as a Programming Model
Ban đầu, Open vSwitch tập trung vào một mô hình lập trình luồng phản ứng (reactive flow programming model), trong đó một bộ điều khiển đáp ứng các lưu lượng cài đặt microflow (trafic install microflows) phù hợp với mọi trường OpenFlow được hỗ trợ. Cách tiếp cận này rất dễ dàng để hỗ trợ cho phần mềm switch và bộ điều khiển (nghiên cứu ban đầu cho thấy nó đáp ứng đủ yêu cầu). Tuy nhiên, lập trình phản ứng của các microflow sớm tỏ ra không thực tế khi sử dụng các triển khai (deployment) lớn và Open vSwitch đã phải thích ứng với lập trình luồng chủ động (proactive flow programming) để hạn chế chi phí hoạt động của nó.

Trong OpenFlow 1.0, một microflow có khoảng 275 bit thông tin, do đó một flow table cho mỗi microflow sẽ có từ $2^{275}$ mục trở lên. Vì vậy, proactive population của flow table yêu cầu hỗ trợ cho wildcard matching để bao gồm không gian tiêu đề của tất cả các gói khả thi. Với một bảng đơn, kết quả là “cross-product problem”: để thay đổi việc xử lý các gói theo $n_1$ giá trị của trường A và $n_2$ giá trị của trường B, ta phải cài đặt $n_1 × n_2$ trong trường hợp tổng quát, ngay cả khi các hành động được thực hiện dựa trên A và B là độc lập. Open vSwitch giới thiệu một action mở rộng được gọi là resubmit cho phép các gói tin tham khảo nhiều bảng lưu lượng (hoặc cùng một bảng nhiều lần) và tổng hợp các hành động kết quả (resulting action). Điều này giải quyết "cross-product problem", vì một bảng có thể chứa luồng $n_1$ tham khảo ý kiến ​​A và một bảng chứa luồng $n_2$ khác tham khảo B. Hành động resubmit cũng cho phép một dạng lập trình dựa trên phân nhánh đa đường (multiway) dựa trên giá trị của một hoặc nhiều trường. Sau đó, các nhà cung cấp (vendor) OpenFlow tập trung vào phần cứng, tìm cách tận dụng tốt hơn nhiều bảng được tham khảo hàng loạt bằng cách phát triển ASIC. OpenFlow 1.1 đã giới thiệu hỗ trợ nhiều bảng. Open vSwitch đã thông qua mô hình mới nhưng vẫn giữ lại sự hỗ trợ của nó cho hành động resubmit để tương thích ngược (backward compatibility) và vì mô hình mới không cho phép đệ quy chỉ chuyển tiếp quá trình (progress) thông qua một pipelines bảng cố định.

Tại thời điểm này, một bộ điều khiển có thể thực hiện các chương trình trong các flow table Open vSwitch, có thể đưa ra quyết định dựa trên các header gói tin bằng cách sử dụng các chuỗi logic tùy ý, nhưng chúng không có quyền truy cập vào bộ nhớ tạm thời. Để giải quyết vấn đề đó, hãy mở vSwitch OpenFlow mở rộng theo cách khác, bằng cách thêm các trường siêu dữ liệu được gọi là "thanh ghi" (register) mà các flow table có thể match, cộng thêm các hành động bổ sung để sửa đổi và sao chép. Ví dụ, các flow có thể quyết định điểm đến vật lý sớm trong pipeline, sau đó run gói tin thông qua các bước xử lý gói giống nhau bất kể đích đã chọn, cho đến khi gửi gói, có thể sử dụng hướng dẫn cụ thể đích. Một ví dụ khác, bộ điều khiển ảo hóa mạng NVP của VMware sử dụng thanh ghi để theo dõi tiến độ (progress) của gói tin thông qua một cấu trúc liên kết logic L2 và L3 được thực hiện dưới dạng “datapath logic” mà nó phủ lên trên pipeline OpenFlow vật lý.

OpenFlow chuyên kiểm soát flow của một switch. Nó không thể tạo hoặc phá hủy các switch OpenFlow, thêm hoặc loại bỏ các cổng, cấu hình hàng đợi QoS, kết nối bộ điều khiển và chuyển mạch OpenFlow, cho phép hoặc vô hiệu hóa STP (Spanning Tree Protocol), v.v. Trong Open vSwitch, chức năng này được điều khiển thông qua một thành phần riêng biệt, ```configuration database```. Để truy cập ```configuration database```, bộ điều khiển SDN có thể kết nối với máy chủ ovSDb qua giao thức OVSDB. Nói chung, trong Open vSwitch, OpenFlow điều khiển dữ liệu có thể thay đổi nhanh và không lâu như flow table, trong khi ```configuration database``` chứa trạng thái bền hơn.